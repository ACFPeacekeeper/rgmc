{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from subprocess import run\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, name, dataset_dir, device, download=False, exclude_modality='none', target_modality='none', train=True, transform=None, adv_attack=None):\n",
    "        super().__init__()\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.exclude_modality = exclude_modality\n",
    "        self.transform = transform\n",
    "        self.adv_attack = adv_attack\n",
    "        self.target_modality = target_modality\n",
    "        self.dataset = {}\n",
    "        self.dataset_len = 0\n",
    "        self.labels = None\n",
    "        self.modalities = None\n",
    "        self._load_data(train)\n",
    "\n",
    "    def _download(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _load_data(self, train):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _show_dataset_label_distribution(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def _get_modalities(self):\n",
    "        return self.modalities\n",
    "    \n",
    "    def _set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def _set_adv_attack(self, adv_attack):\n",
    "        self.adv_attack = adv_attack\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = dict.fromkeys(self.dataset.keys())\n",
    "        for key in data.keys():\n",
    "            data[key] = self.dataset[key][index].type(torch.cuda.FloatTensor)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            labels = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        if self.adv_attack is not None:\n",
    "            if self.labels is not None:\n",
    "                data = self.adv_attack(data, labels)\n",
    "            else:\n",
    "                data = self.adv_attack(data, data)\n",
    "\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MhdDataset(MultimodalDataset):\n",
    "    def __init__(self, dataset_dir, device, download=False, exclude_modality='none', target_modality='none', train=True, transform=None, adv_attack=None):\n",
    "        super().__init__(dataset_dir, device, download, exclude_modality, target_modality, train, transform, adv_attack)\n",
    "\n",
    "    @staticmethod\n",
    "    def _download():\n",
    "        run([os.path.join(os.getcwd(), \"datasets\", \"mhd\", \"download_mhd_dataset.sh\"), \"bash\"], shell=True)\n",
    "        return\n",
    "\n",
    "    def _load_data(self, train):\n",
    "        if train:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mhd_train.pt\")\n",
    "        else:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mhd_test.pt\")\n",
    "        \n",
    "        data = list(torch.load(data_path))\n",
    "        self.dataset_len = len(data[0])\n",
    "\n",
    "        # Normalize datasets\n",
    "        data[1] = (data[1] - torch.min(data[1])) / (torch.max(data[1]) - torch.min(data[1]))\n",
    "        data[2] = (data[2] - torch.min(data[2])) / (torch.max(data[2]) - torch.min(data[2]))\n",
    "\n",
    "        if self.exclude_modality == 'image':\n",
    "            self.dataset = {'image': torch.full(data[1].size(), -1).to(self.device),'trajectory': data[2].to(self.device)}\n",
    "        elif self.exclude_modality == 'trajectory':\n",
    "            self.dataset = {'image': data[1].to(self.device), 'trajectory': torch.full(data[2].size(), -1).to(self.device)}\n",
    "        else:\n",
    "            self.dataset = {'image': data[1].to(self.device), 'trajectory': data[2].to(self.device)}\n",
    "\n",
    "        self.labels = data[0].to(self.device)\n",
    "        return\n",
    "    \n",
    "    def _show_dataset_label_distribution(self):\n",
    "        label_dict = {\"0\": 0, \"1\": 0, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}\n",
    "        \n",
    "        for data_set in ['train', 'test']:\n",
    "            data_path = os.path.join(self.dataset_dir, f\"mhd_{data_set}.pt\")\n",
    "\n",
    "            data = torch.load(data_path)\n",
    "            labels = data[\"labels\"]\n",
    "            dataset_len = len(labels)\n",
    "            for label in labels:\n",
    "                label_dict[str(label.item())] += 1\n",
    "\n",
    "            print(f'Label count: {dataset_len}')\n",
    "            print(label_dict)\n",
    "            X_axis = np.arange(len(label_dict.keys()))\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.figsize=(20, 10)\n",
    "            ax.set_xticks(X_axis)\n",
    "            ax.set_xticklabels(label_dict.keys())\n",
    "            ax.set_title(f\"MHD {data_set} set digit labels\")\n",
    "            ax.yaxis.grid(True)\n",
    "            metrics_bar = ax.bar(X_axis, label_dict.values(), width=1, label=\"Loss values\", align='center', ecolor='black', capsize=10)\n",
    "            ax.bar_label(metrics_bar)\n",
    "            fig.legend()\n",
    "            fig.savefig(os.path.join(self.dataset_dir, f'mhd_{data_set}.png'))\n",
    "            plt.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistSvhnDataset(MultimodalDataset):\n",
    "    def __init__(self, name, dataset_dir, device, download=False, exclude_modality='none', target_modality='none', train=True, transform=None, adv_attack=None, max_d = 10000, dm=30):\n",
    "        super().__init__(name, dataset_dir, device, download, exclude_modality, target_modality, train, transform, adv_attack)\n",
    "        self.max_d = max_d  # maximum number of datapoints per class\n",
    "        self.dm = dm        # data multiplier: random permutations to match \n",
    "        \n",
    "    @staticmethod\n",
    "    def _download():\n",
    "        # Get the individual datasets\n",
    "        tx = transforms.ToTensor()\n",
    "        train_mnist = datasets.MNIST(os.path.join(\"datasets\", \"mnist_svhn\"), train=True, download=True, transform=tx)\n",
    "        test_mnist = datasets.MNIST(os.path.join(\"datasets\", \"mnist_svhn\"), train=False, download=True, transform=tx)\n",
    "        train_svhn = datasets.SVHN(os.path.join(\"datasets\", \"mnist_svhn\"), split='train', download=True, transform=tx)\n",
    "        test_svhn = datasets.SVHN(os.path.join(\"datasets\", \"mnist_svhn\"), split='test', download=True, transform=tx)\n",
    "        # SVHN labels need extra work\n",
    "        train_svhn.labels = torch.LongTensor(train_svhn.labels.squeeze().astype(int)) % 10\n",
    "        test_svhn.labels = torch.LongTensor(test_svhn.labels.squeeze().astype(int)) % 10\n",
    "\n",
    "        train_dict = {\"mnist\": [], \"svhn\": [], \"labels\": []}\n",
    "        svhn_dict = {\"0\": [], \"1\": [], \"2\": [], \"3\": [], \"4\": [], \"5\": [], \"6\": [], \"7\": [], \"8\": [], \"9\": []}\n",
    "        print(\"Exporting svhn train set...\")\n",
    "        for feats, label in tqdm(zip(train_svhn.data, train_svhn.labels), total=len(train_svhn)):\n",
    "            svhn_dict[str(label.item())].append(feats)\n",
    "\n",
    "        mnist_dict = {\"0\": [], \"1\": [], \"2\": [], \"3\": [], \"4\": [], \"5\": [], \"6\": [], \"7\": [], \"8\": [], \"9\": []}\n",
    "        print(\"Exporting mnist train set...\")\n",
    "        for feats, label in tqdm(zip(train_mnist.data, train_mnist.targets), total=len(train_mnist)):\n",
    "            mnist_dict[str(label.item())].append(feats)\n",
    "        \n",
    "        print(\"Combining training datasets...\")\n",
    "        for dig in tqdm(svhn_dict.keys()):\n",
    "            for mnist_feats, svhn_feats in zip(mnist_dict[str(dig)], svhn_dict[str(dig)]):\n",
    "                train_dict[\"mnist\"].append(mnist_feats[None, :])\n",
    "                train_dict[\"svhn\"].append(torch.from_numpy(svhn_feats))\n",
    "                train_dict[\"labels\"].append(torch.tensor(int(dig)))\n",
    "\n",
    "        train_dict[\"mnist\"] = torch.stack(train_dict[\"mnist\"])\n",
    "        train_dict[\"svhn\"] = torch.stack(train_dict[\"svhn\"])\n",
    "        train_dict[\"labels\"] = torch.stack(train_dict[\"labels\"])\n",
    "\n",
    "        test_dict = {\"mnist\": [], \"svhn\": [], \"labels\": []}\n",
    "        svhn_dict = {\"0\": [], \"1\": [], \"2\": [], \"3\": [], \"4\": [], \"5\": [], \"6\": [], \"7\": [], \"8\": [], \"9\": []}\n",
    "        print(\"Exporting svhn test set...\")\n",
    "        for feats, label in tqdm(zip(test_svhn.data, test_svhn.labels), total=len(test_svhn)):\n",
    "            svhn_dict[str(label.item())].append(feats)\n",
    "\n",
    "        mnist_dict = {\"0\": [], \"1\": [], \"2\": [], \"3\": [], \"4\": [], \"5\": [], \"6\": [], \"7\": [], \"8\": [], \"9\": []}\n",
    "        print(\"Exporting mnist test set...\")\n",
    "        for feats, label in tqdm(zip(test_mnist.data, test_mnist.targets), total=len(test_mnist)):\n",
    "            mnist_dict[str(label.item())].append(feats)\n",
    "        \n",
    "        print(\"Combining test datasets...\")\n",
    "        for dig in tqdm(svhn_dict.keys()):\n",
    "            for mnist_feats, svhn_feats in zip(mnist_dict[str(dig)], svhn_dict[str(dig)]):\n",
    "                test_dict[\"mnist\"].append(mnist_feats[None, :])\n",
    "                test_dict[\"svhn\"].append(torch.from_numpy(svhn_feats))\n",
    "                test_dict[\"labels\"].append(torch.tensor(int(dig)))\n",
    "\n",
    "        test_dict[\"mnist\"] = torch.stack(test_dict[\"mnist\"])\n",
    "        test_dict[\"svhn\"] = torch.stack(test_dict[\"svhn\"])\n",
    "        test_dict[\"labels\"] = torch.stack(test_dict[\"labels\"])\n",
    "        \n",
    "        torch.save(train_dict, os.path.join(\"datasets\", \"mnist_svhn\", 'mnist_svhn_train.pt'))\n",
    "        torch.save(test_dict, os.path.join(\"datasets\", \"mnist_svhn\", 'mnist_svhn_test.pt'))\n",
    "        return\n",
    "    \n",
    "    def _load_data(self, train):\n",
    "        if train:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mnist_svhn_train.pt\")\n",
    "        else:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mnist_svhn_test.pt\")\n",
    "\n",
    "        data = torch.load(data_path)\n",
    "        self.dataset_len = len(data[\"labels\"])\n",
    "\n",
    "        # Normalize datasets\n",
    "        data['mnist'] = (data['mnist'] - torch.min(data['mnist'])) / (torch.max(data['mnist']) - torch.min(data['mnist']))\n",
    "        data['svhn'] = (data['svhn'] - torch.min(data['svhn'])) / (torch.max(data['svhn']) - torch.min(data['svhn']))\n",
    "\n",
    "        if self.exclude_modality == 'mnist':\n",
    "            self.dataset = {'mnist': torch.full(data[\"mnist\"].size(), -1).to(self.device), 'svhn': data[\"svhn\"].to(self.device)}\n",
    "        elif self.exclude_modality == 'svhn':\n",
    "            self.dataset = {'mnist': data[\"mnist\"].to(self.device), 'svhn': torch.full(data[\"svhn\"].size(), -1).to(self.device)}\n",
    "        else:\n",
    "            self.dataset = {'mnist': data[\"mnist\"].to(self.device), 'svhn': data[\"svhn\"].to(self.device)}\n",
    "\n",
    "        self.labels = data[\"labels\"].to(self.device)\n",
    "        return\n",
    "    \n",
    "    def _show_dataset_label_distribution(self):\n",
    "        label_dict = {\"0\": 0, \"1\": 0, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}\n",
    "\n",
    "        for data_set in ['train', 'test']:\n",
    "            data_path = os.path.join(self.dataset_dir, f\"mnist_svhn_{data_set}.pt\")\n",
    "\n",
    "            data = torch.load(data_path)\n",
    "            labels = data[\"labels\"]\n",
    "            dataset_len = len(labels)\n",
    "            for label in labels:\n",
    "                label_dict[str(label.item())] += 1\n",
    "\n",
    "            print(f'Label count: {dataset_len}')\n",
    "            print(label_dict)\n",
    "            X_axis = np.arange(len(label_dict.keys()))\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.figsize=(20, 10)\n",
    "            ax.set_xticks(X_axis)\n",
    "            ax.set_xticklabels(label_dict.keys())\n",
    "            ax.set_title(f\"MNIST-SVHN {data_set} set digit labels\")\n",
    "            ax.yaxis.grid(True)\n",
    "            metrics_bar = ax.bar(X_axis, label_dict.values(), width=1, label=\"Loss values\", align='center', ecolor='black', capsize=10)\n",
    "            ax.bar_label(metrics_bar)\n",
    "            fig.legend()\n",
    "            fig.savefig(os.path.join(self.dataset_dir, f'ms_{data_set}.png'))\n",
    "            plt.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoseiDataset(MultimodalDataset):\n",
    "    def __init__(self, dataset_dir, device, download=False, exclude_modality='none', target_modality='none', train=True, transform=None, adv_attack=None):\n",
    "        super().__init__(dataset_dir, device, download, exclude_modality, target_modality, train, transform, adv_attack)\n",
    "\n",
    "    @staticmethod\n",
    "    def _download():\n",
    "        run([os.path.join(os.getcwd(), \"datasets\", \"mosei\", \"download_mosei_dataset.sh\"), \"bash\"], shell=True)\n",
    "        dataset_dir = os.path.join(os.getcwd(), \"datasets\", \"mosei\")\n",
    "        data = torch.load(os.path.join(dataset_dir, \"mosei_train.dt\"))\n",
    "        val_data = torch.load(os.path.join(dataset_dir, \"mosei_valid.dt\"))\n",
    "        dataset = {'text': torch.concat((data.text, val_data.text)), 'audio': torch.concat((data.audio, val_data.audio)), 'vision': torch.concat((data.vision, val_data.vision)), 'labels': torch.concat((data.labels, val_data.labels))}\n",
    "        torch.save(dataset, os.path.join(dataset_dir, \"mosei_train.pt\"))\n",
    "        data = torch.load(os.path.join(dataset_dir, \"mosei_test.dt\"))\n",
    "        dataset = {'text': data.text, 'audio': data.audio, 'vision': data.vision, 'labels': data.labels}\n",
    "        torch.save(dataset, os.path.join(dataset_dir, \"mosei_test.pt\"))\n",
    "        return\n",
    "    \n",
    "    def _load_data(self, train):   \n",
    "        if train:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mosei_train.pt\")\n",
    "            \n",
    "        else:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mosei_test.pt\")\n",
    "\n",
    "        data = torch.load(data_path)\n",
    "        self.dataset = {'text': data['text'].to(self.device), 'audio': data['audio'].to(self.device), 'vision': data['vision'].to(self.device)}\n",
    "        self.labels = data['labels'].to(self.device)\n",
    "\n",
    "        self.dataset_len = len(self.labels)\n",
    "\n",
    "        if self.exclude_modality != 'none' and self.exclude_modality is not None:\n",
    "            self.dataset[self.exclude_modality] = torch.full(self.dataset[self.exclude_modality], -1).to(self.device)\n",
    "\n",
    "        for mod in ['text', 'audio', 'vision']:\n",
    "            if mod != self.exclude_modality:\n",
    "                self.dataset[mod] = (self.dataset[mod] - torch.min(self.dataset[mod])) / (torch.max(self.dataset[mod]) - torch.min(self.dataset[mod]))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosiDataset(MultimodalDataset):\n",
    "    def __init__(self, dataset_dir, device, download=False, exclude_modality='none', target_modality='none', train=True, transform=None, adv_attack=None):\n",
    "        super().__init__(dataset_dir, device, download, exclude_modality, target_modality, train, transform, adv_attack)\n",
    "\n",
    "    @staticmethod\n",
    "    def _download():\n",
    "        run([os.path.join(os.getcwd(), \"datasets\", \"mosi\", \"download_mosi_dataset.sh\"), \"bash\"], shell=True)\n",
    "        dataset_dir = os.path.join(os.getcwd(), \"datasets\", \"mosi\")\n",
    "        data = torch.load(os.path.join(dataset_dir, \"mosi_train.dt\"))\n",
    "        val_data = torch.load(os.path.join(dataset_dir, \"mosi_valid.dt\"))\n",
    "        dataset = {'text': torch.concat((data.text, val_data.text)), 'audio': torch.concat((data.audio, val_data.audio)), 'vision': torch.concat((data.vision, val_data.vision)), 'labels': torch.concat((data.labels, val_data.labels))}\n",
    "        torch.save(dataset, os.path.join(dataset_dir, \"mosi_train.pt\"))\n",
    "        data = torch.load(os.path.join(dataset_dir, \"mosi_test.dt\"))\n",
    "        dataset = {'text': data.text, 'audio': data.audio, 'vision': data.vision, 'labels': data.labels}\n",
    "        torch.save(dataset, os.path.join(dataset_dir, \"mosi_test.pt\"))\n",
    "        return\n",
    "    \n",
    "    def _load_data(self, train):     \n",
    "        if train:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mosi_train.pt\")\n",
    "            \n",
    "        else:\n",
    "            data_path = os.path.join(self.dataset_dir, \"mosi_test.pt\")\n",
    "\n",
    "        data = torch.load(data_path)\n",
    "        self.dataset = {'text': data['text'].to(self.device), 'audio': data['audio'].to(self.device), 'vision': data['vision'].to(self.device)}\n",
    "        self.labels = data['labels'].to(self.device)\n",
    "\n",
    "        self.dataset_len = len(self.labels)\n",
    "\n",
    "        if self.exclude_modality != 'none' and self.exclude_modality is not None:\n",
    "            self.dataset[self.exclude_modality] = torch.full(self.dataset[self.exclude_modality], -1).to(self.device)\n",
    "\n",
    "        for mod in ['text', 'audio', 'vision']:\n",
    "            if mod != self.exclude_modality:\n",
    "                self.dataset[mod] = (self.dataset[mod] - torch.min(self.dataset[mod])) / (torch.max(self.dataset[mod]) - torch.min(self.dataset[mod]))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataset(m_path, dataset_name, device=\"cpu\", train=True):\n",
    "    if dataset_name == 'mhd':\n",
    "        dataset = MhdDataset('mhd', os.path.join(m_path, \"datasets\", \"mhd\"), device, False, None, None, train)\n",
    "    elif dataset_name == 'mosi':\n",
    "        dataset = MosiDataset('mosi', os.path.join(m_path, \"datasets\", \"mosi\"), device, False, None, None, train)\n",
    "    elif dataset_name == 'mosei':\n",
    "        dataset = MoseiDataset('mosei', os.path.join(m_path, \"datasets\", \"mosei\"), device, False, None, None, train)\n",
    "    elif dataset_name == 'mnist_svhn':\n",
    "        dataset = MnistSvhnDataset('mnist_svhn', os.path.join(m_path, \"datasets\", \"mnist_svhn\"), device, False, None, None, train)\n",
    "    return dataset\n",
    "\n",
    "m_path = os.path.split(os.getcwd())[0]\n",
    "mhd_dataset = setup_dataset(m_path, \"mhd\")\n",
    "mosi_dataset = setup_dataset(m_path, \"mosi\")\n",
    "mosei_dataset = setup_dataset(m_path, \"mosei\")\n",
    "ms_dataset = setup_dataset(m_path, \"mnist_svhn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
